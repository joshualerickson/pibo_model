---
title: "Devil's Advocate"
author: "Josh Erickson"
date: "12/2/2021"
output: html_document
---
```{r, include=F}
library(latex2exp)
knitr::opts_chunk$set(dev.args = list(png = list(type = "cairo")),fig.width = 10, fig.height = 5,
                      warning = FALSE, message = FALSE, error = FALSE)

#can change font to whatever, i like Montserrat
thematic::thematic_on(font = 'Montserrat')

# makes the plots sharper
resourceviz::cairo_view()

library(patchwork)
library(tidyverse)
library(GGally)
library(ggtext)
library(sasLM)
library(janitor)
library(car)
library(broom)
library(ggpubr)
library(rstatix)
library(readxl)
library(sf)
pibo_sites <- read_sf('pibo_sites.gpkg', 'pibo_sites')

gr_95_new <- read_xlsx('C:/Users/joshualerickson/Box/PIBO and Water Yield/Data/R1WestPIBO110521.xlsx') %>% 
  clean_names()

gr_95 <- read_csv('SummaryStatsKendall_gr_95.csv')[,1:36] %>% 
  na.omit() %>%
  clean_names() %>% 
  right_join(gr_95_new %>% select(site_id), by = 'site_id') %>%
  mutate(precip_cut = cut_interval(ave_annual_precip,n=6),
         shed_cut = cut_interval(shed_areakm2, n = 6),
         mgmt = factor(mgmt))

source('utils.R')
group_bf <- gr_95 %>% filter(mgmt == 'Managed') %>% 
  mutate(impact_harvest = pct_high_harv_int+pct_mod_harv_int,
         impact_fire = pct_mtbs_high+pct_mtbs_mod,
         norm_bf = mean_bf/(ave_annual_precip*0.001),
           harvest_group = ifelse(impact_harvest <= 5, 'Low',
                          ifelse(impact_harvest > 5 & impact_harvest <= 20, 'Mod','High')),
           harvest_group = factor(harvest_group, levels = c('Low','Mod', 'High')),
           road_group = ifelse(road_dens_km2 <= 2.59, 'Low',
                          ifelse(road_dens_km2 > 2.59 & road_dens_km2 <= 6.21597, 'Mod','High')),
           road_group = factor(road_group, levels = c('Low','Mod', 'High')),
           fire_group = ifelse(impact_fire <= 5, 'Low',
                          ifelse(impact_fire > 5 & impact_fire <= 20, 'Mod','High')),
          fire_group = factor(fire_group, levels = c('Low','Mod', 'High'))) 

pibo_sites <- pibo_sites %>% left_join(group_bf %>% select(contains('impact'), contains('group'), norm_bf, site_id))
```


## Goals  

1. See if management (roads, harvest and fire) contribute to the narrowing of streams.  
2. See if resampling can help with results.

## Findings  

* When comparing managment only sites, low harvest (<= 5%) and high harvest (> 20%) show no statistically significant difference (resampled p value = 0.199) but low harvest and moderate harvest (> 5% and <= 20%) sites do-ish (resampled p value = 0.0572).   

* In the original analysis the resampled p value was 0.2668, which tells us a little more on how randomly sampling can help tease out some of the confounding factors that might be embedded in the design.  

## Intro  

It was buggin me a little bit that there was a difference between managed and reference mean bankfull widths. Let me rephrase that, I wasn't upset there was a difference per se but was upset that there was a lot of 'causation' surrounding that difference that to me seemed hard to derive from the design. So I wanted to test those claims and see how the 'managed' only data would do under the same assumptions; roads, fire and harvest are driving the narrower stream bankfull measurements. To do this we'll need some help from other studies and some wiggly cutoffs but hopefully we'll be able to see if the 'difference' claim holds true for the 'managed' only sites. Also, we'll dive back into the 'resampling' method I displayed in the ANCOVA write-up.  

## Dive-in  

Let's look at some plots to see what harvest would look like if we broke it into three groups; low <= 5 %, moderate > 5% and <= 20%, high > 20 %. Based on what we found in the other analysis is that managed sites tend to be narrower due to 'treatment', e.g. roads, fire and harvest. Thus, we should see the same trend right?  

First see the count between groups then graph.  

```{r}
group_bf %>% count(harvest_group)
```

```{r, echo = F}
group_bf %>% 
  ggplot(aes(shed_areakm2, mean_bf)) +
  geom_point(alpha = 1, size = 2.5, aes( color = harvest_group))+
    geom_point(shape = 1,size = 2.5, aes( color = harvest_group),colour = "black")+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  #geom_smooth(method = 'lm', se = F, alpha = 0.1)+
  stat_smooth(geom='line', aes(shed_areakm2, mean_bf, group = harvest_group), size = 1.75, se=FALSE, method = 'lm')+
  stat_smooth(geom='line', alpha=1, aes(color = harvest_group),size = 1, se=FALSE, method = 'lm')+
  scale_color_manual(values = c('forestgreen', 'yellow', 'red'))+
  scale_x_log10()+
  custom_theme()  +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Harvest Impact',
       title = 'Comparing Harvest Impacts by Watershed Area and Mean Bankfull Width')
```

We can see that this claim kind of holds for the managed only data as well, i.e. higher disturbance equals narrower stream widths.  

Let's check the others; roads and fire.  

```{r, echo = F}
group_bf %>% 
  ggplot(aes(shed_areakm2, mean_bf)) +
  geom_point(alpha = 1, size = 2.5, aes( color = fire_group))+
    geom_point(shape = 1,size = 2.5, aes( color = fire_group),colour = "black")+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  #geom_smooth(method = 'lm', se = F, alpha = 0.1)+
  stat_smooth(geom='line', aes(shed_areakm2, mean_bf, group = fire_group), size = 1.75, se=FALSE, method = 'lm')+
  stat_smooth(geom='line', alpha=1, aes(color = fire_group),size = 1, se=FALSE, method = 'lm')+
  scale_color_manual(values = c('forestgreen', 'yellow', 'red'))+
  scale_x_log10()+
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Fire Impact',
       title = 'Comparing Fire Impacts by Watershed Area and Mean Bankfull Width')

group_bf %>% 
  ggplot(aes(shed_areakm2, mean_bf)) +
  geom_point(alpha = 1, size = 2.5, aes( color = road_group))+
    geom_point(shape = 1,size = 2.5, aes( color = road_group),colour = "black")+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  #geom_smooth(method = 'lm', se = F, alpha = 0.1)+
  stat_smooth(geom='line', aes(shed_areakm2, mean_bf, group = road_group), size = 1.75, se=FALSE, method = 'lm')+
  stat_smooth(geom='line', alpha=1, aes(color = road_group),size = 1, se=FALSE, method = 'lm')+
  scale_color_manual(values = c('forestgreen', 'yellow', 'red'))+
  scale_x_log10()+
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Road Impact',
       title = 'Comparing Road Impacts by Watershed Area and Mean Bankfull Width')
```

Sort of but not as telling as harvest... Now what if we combined (just add the factors together)? We should see that progression as well right? We do! The more disturbance the narrower the streams are. Crazy right!?  

```{r, echo = F}
group_bf %>% 
  mutate(all_groups = as.numeric(harvest_group)+as.numeric(road_group)+as.numeric(fire_group)) %>% 
  ggplot(aes(shed_areakm2, mean_bf, color = factor(all_groups))) +
  geom_point(alpha = 0.2)+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  geom_smooth(method = 'lm', se = F)+
  scale_x_log10()+
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'All Impacts',
       title = 'Comparing All Impacts by Watershed Area and Mean Bankfull Width')
```

Well, let's hold on a sec. What about other factors like location, topography and such? Ok, ok, sure. We'll look at different precip zones then; 0-950, 950-1300, 1300 +.   
 
```{r, echo = F}
group_bf %>% 
  mutate(all_groups = as.numeric(harvest_group)+as.numeric(road_group)+as.numeric(fire_group),
         precip_cut = ifelse(ave_annual_precip <= 950, 'Low', ifelse(ave_annual_precip >  950 & ave_annual_precip <= 1300, 'Mod', 'High')),
         precip_cut = factor(precip_cut, levels = c('Low', 'Mod', 'High'))) %>% 
  ggplot(aes(shed_areakm2, mean_bf)) +
  geom_point(alpha = 1, size = 2.5, aes( color = precip_cut))+
    geom_point(shape = 1,size = 2.5, aes( color = precip_cut),colour = "black")+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  #geom_smooth(method = 'lm', se = F, alpha = 0.1)+
  stat_smooth(geom='line', aes(shed_areakm2, mean_bf, group = precip_cut), size = 1.75, se=FALSE, method = 'lm')+
  stat_smooth(geom='line', alpha=1, aes(color = precip_cut),size = 1, se=FALSE, method = 'lm')+
  scale_color_manual(values = c('forestgreen', 'yellow', 'red'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Precipitation Zones',
       title = 'Comparing Precipitation Zones by Watershed Area and Mean Bankfull Width')
```

Or just colored by gradient.  

```{r, echo=F}
group_bf %>% 
  mutate(all_groups = as.numeric(harvest_group)+as.numeric(road_group)+as.numeric(fire_group),
         precip_cut = ifelse(ave_annual_precip <= 950, 'Low', ifelse(ave_annual_precip >  950 & ave_annual_precip <= 1300, 'Mod', 'High'))) %>% 
  ggplot(aes(shed_areakm2, mean_bf, color = ave_annual_precip)) +
  geom_point() +
  scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Precipitation (mm)',
       title = 'Comparing Precipitation by Watershed Area and Mean Bankfull Width')
```

Weird. This looks really really similar to what we had shown before right? Could this be influencing our 'casual' assumptions more than the 'treatment' idea? Not positive but I think it's a start.  

Let's normalize the first graph by precipitation and then see if that trend still is relevant.    

```{r, echo = F}
group_bf %>% 
  ggplot(aes(shed_areakm2, norm_bf)) +
  geom_point(alpha = 1, size = 2.5, aes( color = harvest_group))+
    geom_point(shape = 1,size = 2.5, aes( color = harvest_group),colour = "black")+
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  #geom_smooth(method = 'lm', se = F, alpha = 0.1)+
  stat_smooth(geom='line', aes(shed_areakm2, norm_bf, group = harvest_group), size = 1.5, se=FALSE, method = 'lm')+
  stat_smooth(geom='line', alpha=1, aes(color = harvest_group),size = 1, se=FALSE, method = 'lm')+
  scale_color_manual(values = c('forestgreen', 'yellow', 'red'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width/AAP',
       color = 'Harvest Impact',
       title = 'Comparing Harvest Impact by Watershed Area and Normalized Bankfull',
       subtitle =  expression(paste("normalized bankfull =  ", frac('mean bankfull width (m)', 'average annual precipitation (m)'))))
```

Interesting... The trend kind of disappears. This is why I think it is hard to do this analysis in a 'treatment/control' kind of way when the design is not necessarily meant for that type of analysis. Eric has reiterated numerous times about the critiques of PIBO, e.g. not apples to apples. I think this is really important. That is to say, we could have the best model or statistician doing the analysis but if the experimental design is uncontrollable then we get stuck, which makes it hard to come to any conclusions (or articulate any findings). I'm not saying this isn't meaningful... I'm just saying it's more exploratory than confirmatory (IMO).   
<br>
<center>
<img src='design.jpg'>
</center>
<br>

So we can see that the difference changes so should we continue then? Sure, I don't see a problem following it up and seeing if the `harvest impact` has any legs. So we'll do that below.  

Difference vs No difference
```{r}
library(kableExtra)
mod1 <- lm(mean_bf~log(shed_areakm2)+harvest_group, data = group_bf)
broom::tidy(summary(mod1)) %>% kableExtra::kable() %>% kable_styling()

mod2 <- lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + harvest_group, data = group_bf)
broom::tidy(summary(mod2)) %>% kableExtra::kable() %>% kable_styling()

```

We'll need to check assumptions of course, etc.  

```{r, echo = FALSE}

#checking homogeneity of slopes
#precip
g <- lm(mean_bf~log(ave_annual_precip)*harvest_group, data = group_bf)
broom::tidy(summary(g)) %>% kableExtra::kable() %>% kable_styling()
#passed

#watershed area
g <- lm(mean_bf~log(shed_areakm2)*harvest_group, data = group_bf)
broom::tidy(summary(g)) %>% kableExtra::kable() %>% kable_styling()
#passed

#now check normality of residuals
performance::check_normality(mod2)
qqPlot(mod2)
#didn't pass

group_bf$residuals <- mod2$residuals

mod_filt <- lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + harvest_group, data = group_bf %>% 
                 filter(residuals < 5.4))
mod_filt <- lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + harvest_group, data = group_bf %>% 
                 filter(residuals < 5.4))

performance::check_normality(mod_filt)
#passed now; only lose 3 sites 
qqPlot(mod_filt)

```
```{r}
broom::tidy(lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + harvest_group, data = group_bf %>% filter(residuals < 5.4))) %>% kable() %>% kable_styling()
```

We pass the assumptions and also see that there is now a lower p value with bankfull width and harvest impact groups. What's interesting is the estimates for 'Low' and 'High' are closer (difference in means) than the difference between the 'Mod' and 'Low'... Again, so what? I think that it just adds to the complexity of a natural system and how as practitioners we need to continue to learn and grow but also be aware of what this can tell us, e.g. NHST. From the dive above it looks like we tend to log in drier-ish areas, which tend to be narrower streams. Also there is a confusing (against our theory) of high being different from low. Going back to the original analysis (managed vs reference) we could look at the amount of drier locations and compared to each other below. Maybe this will give us a little more clarity on how 'different' our locations are? Looks like there is a lot more of the drier locations in managed.  

```{r, echo=FALSE}
gr_95 %>% 
  mutate(
         precip_cut = ifelse(ave_annual_precip <= 950, 'Low', ifelse(ave_annual_precip >  950 & ave_annual_precip <= 1300, 'Mod', 'High'))) %>% filter(precip_cut=='Low') %>% 
  ggplot(aes(shed_areakm2, mean_bf)) +
  geom_point(aes(color = precip_cut), size = 2.5) +
  geom_point(data = gr_95, aes(shed_areakm2, mean_bf), alpha = 0.075) +
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Precipitation (mm)',
       title = 'Comparing Low Precip by Watershed Area and Mean Bankfull Width',
       subtitle = 'low precip is <= 950 mm or 37.4 inches') +
  facet_wrap(~mgmt)

gr_95 %>% 
  mutate(
         precip_cut = ifelse(ave_annual_precip <= 950, 'Low', ifelse(ave_annual_precip >  950 & ave_annual_precip <= 1300, 'Mod', 'High'))) %>% 
  ggplot(aes(shed_areakm2, mean_bf, color = ave_annual_precip)) +
  geom_point() +
  scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Precipitation (mm)',
       title = 'Comparing Precip by Watershed Area and Mean Bankfull Width') +
  facet_wrap(~mgmt)
```

Isn't ANCOVA supposed to account for this? Well, kind of... My interpretation from this is ANCOVA is telling us that it's important to use management/reference to predict bankfull width because there is a difference between their locations aka sites hydrophysiographic properties and we can't tell if there is a treatment effect because our design is not appropriate. Let's try and compare apples to apples then right? Let's take out all the 'low' precip areas then.  

```{r, echo=F}
example <- gr_95 %>% 
  mutate(
         precip_cut = ifelse(ave_annual_precip <= 950, 'Low', ifelse(ave_annual_precip >  950 & ave_annual_precip <= 1300, 'Mod', 'High'))) 

example_man <- example %>% 
  filter(precip_cut %in% c('High', 'Mod') & mgmt == 'Managed') 
example_ref <- example %>% filter(mgmt == 'Reference')
  
example <- bind_rows(example_man, example_ref)
#gr_95 %>% filter(residuals_og < 6) %>% 
```
```{r,echo=FALSE}
 example %>% 
  ggplot(aes(shed_areakm2, mean_bf, color = mgmt)) +
  geom_point() +
  geom_smooth(method = 'lm', se = F) +
  #scale_color_gradientn(colours = wesanderson::wes_palette('Zissou1'))+
  scale_x_log10() +
  custom_theme() +
  labs(x = 'Watershed Area km<sup>2</sup>',
       y = 'Mean Bankfull Width (m)',
       color = 'Precipitation (mm)',
       title = 'Comparing Watershed Area and Mean Bankfull Width',
       subtitle = 'after taking out all precip <= 950 mm') 
```

```{r,echo=F}
#summary(lm(mean_bf~log(ave_annual_precip)*mgmt, data = example))
mod_examp <- lm(mean_bf~log(shed_areakm2)+log(ave_annual_precip)+mgmt, data = example)
example$residuals_examp <- mod_examp$residuals
#summary(mod_examp)
#qqPlot(mod_examp)
mod_examp <- lm(mean_bf~log(shed_areakm2)+log(ave_annual_precip)+mgmt, data = example %>% filter(residuals_examp<6))

#qqPlot(mod_examp)
#shapiro.test(mod_examp$residuals)

```

After checking assumptions and running ANCOVA we see we are now at a 0.06 p value. Awesome, not able to reject NULL...? 
```{r}
broom::tidy(summary(mod_examp)) %>% kable() %>% kable_styling()
```
If you haven't realized by now I'm not too stoked on p value or associating cause without the proper experimental design. Again, that's not saying there isn't a treatment effect it's just our sample may not be the best representation of the experiment (sampling bias). Also, I noticed there are more co-located sites than I thought in the which could maybe explain some of the potential overfitting and iid assumptions being violated.  

Below is just a map of the areas and harvest groups that gives an idea of some of these _colocated_ sites. Pink polygons are wilderness. Colors are low = 'green', mod = 'yellow', high = 'red'; for harvest impact using the 0-5, 5-20, 20 + (groups).   

```{r, echo=FALSE}
library(ggplot2)
library(plotly)
library(leaflet)
pb <- pibo_sites %>% filter(!is.na(harvest_group))
# map
harv <- colorFactor(palette = c('green', 'yellow', 'red'), pb$harvest_group)
lf <- hydroapps:::base_map() %>% 
  addWMSTiles(baseUrl = 'https://apps.fs.usda.gov/arcx/services/EDW/EDW_Wilderness_01/MapServer/WmsServer?', layers = '0',
                                             options = leaflet::WMSTileOptions(format = "image/png", 
                                 transparent = TRUE)) %>% 
  addCircleMarkers(data = pb,fillColor = ~harv(harvest_group),
                                                               fillOpacity = 0.9, opacity = 0, popup = paste('<b>Harvest Impact: </b>', pb$harvest_group))

lf


```



This is why I like randomly sampling the data and then testing the hypothesis over and over again. The hope is a pattern will start to form because we'll be **_randomly sampling_** and if there is an effect it should show it's head, amirit? We'll do that below. For example, we'll take the data from both reference and managed and randomly sample 80 sites from each; check the assumptions; then see how common the p values are for 0.05 and below; but, we'll do this 100,000 times (because we'll get NA's sometimes due to not following assumptions it will only be around 22,000 tests).  


```{r, eval=FALSE, echo=FALSE}
results <- data.frame()
for(i in 1:100000){
  
  managed <- gr_95 %>% filter(mgmt == 'Managed') %>% slice_sample(n = 80)
  reference <- gr_95 %>% filter(mgmt == 'Reference') %>% slice_sample(n = 80)

  all_together <- bind_rows(managed, reference) %>% mutate(mgmt = factor(mgmt))
  mod <- lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + mgmt, data = all_together)
  h_mod1 <- broom::tidy(lm(mean_bf~log(shed_areakm2)*mgmt, data = all_together))[4,'p.value']
  h_mod2 <- broom::tidy(lm(mean_bf~log(ave_annual_precip)*mgmt, data = all_together))[4,'p.value']
  
  log1 <- all(h_mod1$p.value > 0.05)
  log2 <- all(h_mod2$p.value > 0.05)
  
  norm_resid <- shapiro.test(mod$residuals)$p.value > 0.05
  
  if(all(log1, log2, norm_resid)){
    
    results1 <- broom::tidy(mod)[4,c('term','p.value')]
    
  } else {
    
    results1 <- data.frame(term = c('mgmtReference'),
                          p.value = c(NA_real_))
  }
  
  results <- plyr::rbind.fill(results, results1)
}

write_csv(results, 'results_for_sampling.csv')

```

```{r, echo=FALSE}
results <- read_csv('results_for_sampling.csv')
results %>% 
  ggplot(aes(p.value)) +
  geom_histogram() +
  scale_x_log10(labels = scales::comma_format(accuracy = 0.001)) +
  geom_vline(xintercept = 0.05, col = 'red', linetype = 2) + 
  geom_vline(xintercept = 0.2668, col = 'red', size = 1)+
  custom_theme() +
  annotate(geom = 'text', x = 0.01, y = 2000,  label = '0.05')+
  annotate(geom = 'segment', x = 0.015, xend = 0.045, y = 2000, yend = 2000,
           arrow = arrow(length=unit(0.30,"cm")))  +
  annotate(geom = 'text', x = 0.005, y = 2500,  label = '0.2668\nmean')+
  annotate(geom = 'segment', x = 0.01, xend = 0.25, y = 2500, yend = 2500,
           arrow = arrow(length=unit(0.30,"cm")))+
  labs(title = 'Resampled ANCOVA for Mean Bankfull Width',
       subtitle = 'about 22,000 samples/tests')

rows_with_p_ls_05 <- results %>% filter(p.value <=0.05, !is.na(p.value)) %>% nrow()
rows_total <- results %>% filter(!is.na(p.value)) %>% nrow()

cat('Percent less than 0.05: ', 100*(rows_with_p_ls_05/rows_total), ' %')
mean(results$p.value, na.rm = T)
```

We can see that only 19 % of the results are less than or equal to 0.05 and that the mean is `r round(100*mean(results$p.value, na.rm = T), 2)`.  

What about for the harvest question and narrowing streams. Well let's do the same thing and see what kind of estimates we get.  

```{r, echo=FALSE, eval=FALSE}

results <- data.frame()
for(i in 1:100000){
  
  managed <- group_bf %>% filter(mgmt == 'Managed') %>% slice_sample(n = 150)

  all_together <- managed %>% mutate(mgmt = factor(mgmt))
  mod <- lm(mean_bf~log(shed_areakm2) + log(ave_annual_precip) + harvest_group, data = all_together)
  h_mod1 <- broom::tidy(lm(mean_bf~log(shed_areakm2)*harvest_group, data = all_together))[5:6,'p.value']
  h_mod2 <- broom::tidy(lm(mean_bf~log(ave_annual_precip)*harvest_group, data = all_together))[5:6,'p.value']
  
  log1 <- all(h_mod1$p.value > 0.05)
  log2 <- all(h_mod2$p.value > 0.05)
  
  norm_resid <- shapiro.test(mod$residuals)$p.value > 0.05
  
  if(all(log1, log2, norm_resid)){
    
    results1 <- broom::tidy(mod)[4:5,c('term','estimate','p.value')]
    
  } else {
    
    results1 <- data.frame(term = c('harvest_groupMod', 'harvest_groupHigh'),
                          p.value = c(NA_real_, NA_real_),
                          estimate = c(NA_real_, NA_real_))
  }
  
  results <- plyr::rbind.fill(results, results1)
}

write_csv(results, 'results_for_sampling_harvest.csv')

```

```{r, echo=F}
results2 <- read_csv('results_for_sampling_harvest.csv')
results2 %>% 
  ggplot(aes(p.value, fill = term)) +
  geom_histogram() +
  scale_x_log10(labels = scales::comma_format(accuracy = 0.001)) +
  geom_vline(xintercept = 0.05, col = 'red') + custom_theme() +
  annotate(geom = 'text', x = 0.01, y = 200,  label = '0.05')+
  annotate(geom = 'segment', x = 0.015, xend = 0.045, y = 200, yend = 200,
           arrow = arrow(length=unit(0.30,"cm"))) +
  labs(title = 'Resampled ANCOVA for Mean Bankfull Width',
       subtitle = 'about 2,000 samples/tests')

rows_with_p_ls_05 <- results2 %>% filter(p.value <=0.05, !is.na(p.value), term == 'harvest_groupHigh') %>% nrow()
rows_total <- results2 %>% filter(!is.na(p.value), term == 'harvest_groupHigh') %>% nrow()

cat('Percent less than 0.05 harvest_groupHigh: ', 100*(rows_with_p_ls_05/rows_total), ' %')

rows_with_p_ls_05_mod <- results2 %>% filter(p.value <=0.05, !is.na(p.value), term == 'harvest_groupMod') %>% nrow()
rows_total <- results2 %>% filter(!is.na(p.value), term == 'harvest_groupMod') %>% nrow()

cat('Percent less than 0.05 for harvest_groupMod: ', 100*(rows_with_p_ls_05_mod/rows_total), ' %')
mean(results$p.value, na.rm = T)
```

From the graph above it looks like the `harvest_groupMod` is most likely different and the `harvest_groupHigh` isn't when compared to `harvest_groupLow`. So what? Right, so what. My brain hurts... Again, can we use any of this workflow?  

<br>
<br>
<br>
<br>
<br>
<br>
